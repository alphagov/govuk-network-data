{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T22:25:18.514590Z",
     "start_time": "2019-03-02T22:25:16.257846Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# progress bar\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "# instantiate progress bar goodness\n",
    "tqdm.pandas(tqdm_notebook)\n",
    "\n",
    "# print long str\n",
    "pd.set_option('max_colwidth',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T19:05:39.544111Z",
     "start_time": "2019-03-02T19:05:39.541024Z"
    }
   },
   "outputs": [],
   "source": [
    "page_of_interest = \"/help/cookies\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The problem\n",
    "We are interested in inspecting user journeys to determine whether a specific page is disruptive to those journeys, let's call it Page X. We use some pseudocode art to describe what we mean informerly:\n",
    "\n",
    "**Succesful or undisrupted journey**  \n",
    "A -> X -> A\n",
    "\n",
    "**Unsuccesful or disrupted journey**    \n",
    "A -> X -> NOT A  \n",
    "A -> X -> Exit\n",
    "\n",
    "Where `A` is a node in a journey immediately prior to `X` (`A` can be any page except `X`). A succesful or not disrupted journey, will be looped, that is a user will travel to `X` from `A`, then return back to `A` again, continuing their journey undisrupted. An unsuccesful journey or disrupted journey is considered to be anything else, including the user leaving the site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using this notebook\n",
    "This notebook is written for those new to Python. Accordingly, we don't always use the most Pythonic or efficient code. Instead we opt for code that is most explicit and easy to follow with lots of examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File/dir locations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a recent processed_journey dataset derived from using this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T19:05:39.551315Z",
     "start_time": "2019-03-02T19:05:39.546120Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.getenv(\"DATA_DIR\")\n",
    "filename = \"full_sample_taxon_ab_2019_947858.csv.gz\"\n",
    "df_file = os.path.join(\n",
    "    DATA_DIR, \"processed_journey\",\n",
    "    filename)\n",
    "\n",
    "print(df_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load up a data file that isn't too large. Here we use a sampled dataset from a week's worth of data of the 21-27 Jan 2019. It includes A and B variants but we can just merge the same journeys on the different variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T19:05:55.223668Z",
     "start_time": "2019-03-02T19:05:39.556425Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(df_file, compression=\"gzip\", sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T19:08:05.576922Z",
     "start_time": "2019-03-02T19:05:55.227191Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert from str to list\n",
    "df['Event_cat_act_agg']= df['Event_cat_act_agg'].progress_apply(ast.literal_eval)\n",
    "df['Page_Event_List'] = df['Page_Event_List'].progress_apply(ast.literal_eval)\n",
    "df['Page_List'] = df['Page_List'].progress_apply(ast.literal_eval)\n",
    "df['Page_List_Length'] = df['Page_List'].progress_apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T19:08:05.625937Z",
     "start_time": "2019-03-02T19:08:05.579485Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T19:08:05.919680Z",
     "start_time": "2019-03-02T19:08:05.628824Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Page_List approach\n",
    "We are interested in counting each of the different types of journey given in the problem definition.\n",
    "\n",
    "**Succesful or undisrupted journey**  \n",
    "A -> X -> A\n",
    "\n",
    "**Unsuccesful or disrupted journey**    \n",
    "A -> X -> NOT A  \n",
    "A -> X -> Exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering relevant journeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does a journey or Page_List include your page_of_interest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T19:08:05.927719Z",
     "start_time": "2019-03-02T19:08:05.922027Z"
    }
   },
   "outputs": [],
   "source": [
    "# does each journey contain page_of_interest?\n",
    "df.Page_List.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T19:08:05.934601Z",
     "start_time": "2019-03-02T19:08:05.930332Z"
    }
   },
   "outputs": [],
   "source": [
    "def journey_of_interest(page_list):\n",
    "    \"\"\"Checks whether page_of_interest occurs in a page_list.\n",
    "    \n",
    "    Where a page_list is a journey and page_of_interest is\n",
    "    a global variable.\n",
    "    \n",
    "    \"\"\"\n",
    "    if page_of_interest in page_list:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T19:08:05.941900Z",
     "start_time": "2019-03-02T19:08:05.937633Z"
    }
   },
   "outputs": [],
   "source": [
    "journey_of_interest([\"A\", page_of_interest, \"A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T19:08:05.948329Z",
     "start_time": "2019-03-02T19:08:05.943773Z"
    }
   },
   "outputs": [],
   "source": [
    "journey_of_interest([\"A\", page_of_interest, \"B\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T19:08:05.955700Z",
     "start_time": "2019-03-02T19:08:05.950669Z"
    }
   },
   "outputs": [],
   "source": [
    "journey_of_interest([\"A\", \"A\", \"B\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T19:08:06.249622Z",
     "start_time": "2019-03-02T19:08:05.958247Z"
    }
   },
   "outputs": [],
   "source": [
    "df['contains_page_of_interest'] = df['Page_List'].apply(journey_of_interest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T19:08:06.266164Z",
     "start_time": "2019-03-02T19:08:06.251774Z"
    }
   },
   "outputs": [],
   "source": [
    "df.contains_page_of_interest.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter for journeys that contain the page_of_interest\n",
    "We reduce the number of rows we are working with. How many unique journeys does our data contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T19:08:06.277530Z",
     "start_time": "2019-03-02T19:08:06.268313Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# As it's a logical variable we keep the rows that were True for Contains_page_of_interest\n",
    "df = df[df['contains_page_of_interest']]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how many sessions occurred across these journeys?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T19:17:36.594030Z",
     "start_time": "2019-03-02T19:17:36.589021Z"
    }
   },
   "outputs": [],
   "source": [
    "df.Occurrences.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where in the Page_List does the page_of_interest occurr?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We probably want to know where it happens in a journey, so that we can extract the previous page and the next page, in order to assign the journey as undistrupted or distrupted. We do that using a Pythonic [list comprehension](https://www.digitalocean.com/community/tutorials/understanding-list-comprehensions-in-python-3) approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T19:08:06.283191Z",
     "start_time": "2019-03-02T19:08:06.279818Z"
    }
   },
   "outputs": [],
   "source": [
    "def where_page_of_interest(page_list):\n",
    "    \"\"\"Return the indices of where the page of interest occurs in the page_list.\"\"\"\n",
    "    indices = [i for i, x in enumerate(page_list) if x == page_of_interest]\n",
    "    return indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T19:08:07.013680Z",
     "start_time": "2019-03-02T19:08:06.285882Z"
    }
   },
   "outputs": [],
   "source": [
    "df['where_page_of_interest'] = df['Page_List'].apply(where_page_of_interest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T19:08:27.717989Z",
     "start_time": "2019-03-02T19:08:27.663920Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is a journey disrupted by the page_of_interest?\n",
    "We are interested in retrieving the pages before and after the `page_of_interest`. Given the newly created variable `where_page_of_interest` provides us with the index in the page list of where it was seen, we can simply extract the page at plus and minus one of this page, and then ask if it is the same page? If it is the same page, the user carried on their journey as usual and it was not disrupted, if the page were different then it was considered a disrupted journey. A user may also leave the site, so if no page exists beyond the `page_of_interest` we should probably count this as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does a journey end with the page_of_interest?\n",
    "Does the max where_page_of_interest in a row equal the Page_List_Length minus one? (is it the last page in the journey aka the \"exit page\"; we minus one because of zero indexing in Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T21:58:45.624262Z",
     "start_time": "2019-03-02T21:58:45.620914Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_page_of_interest_exit(page_list_length, where_page_of_interest):\n",
    "    \"\"\"Does the last page in a journey equal the page of interest?\"\"\"\n",
    "    return where_page_of_interest[-1] == (page_list_length-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T21:58:45.824966Z",
     "start_time": "2019-03-02T21:58:45.819985Z"
    }
   },
   "outputs": [],
   "source": [
    "is_page_of_interest_exit(3, [0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T22:00:40.138686Z",
     "start_time": "2019-03-02T22:00:40.121474Z"
    }
   },
   "outputs": [],
   "source": [
    "df['page_of_interest_exit'] = df.apply(lambda row: is_page_of_interest_exit(row['Page_List_Length'], row['where_page_of_interest']) , axis = 1)\n",
    "df.page_of_interest_exit.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can determine the proportion of users exiting a journey or their session on the page_of_interest as a proportion between zero and one. However, this is just a proportion of journey types rather than considering the number of Occurrences or sessions where this is true, thus it is misleading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T22:04:08.028945Z",
     "start_time": "2019-03-02T22:04:08.024188Z"
    }
   },
   "outputs": [],
   "source": [
    "df.page_of_interest_exit.sum() / len(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider occurrences, as in how frequently this page_of_interest was associated with the end of a journey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T22:23:25.250509Z",
     "start_time": "2019-03-02T22:23:25.242930Z"
    }
   },
   "outputs": [],
   "source": [
    "# create new variable\n",
    "df['page_of_interest_exit_occurrences'] = 0\n",
    "df.loc[df.page_of_interest_exit == True, 'page_of_interest_exit_occurrences'] = df['Occurrences']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can calculate the number of sessons that exited on this page of interest as a proportion of all sessions that touched the page_of_interest at least once in their journey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T22:32:35.089108Z",
     "start_time": "2019-03-02T22:32:35.083470Z"
    }
   },
   "outputs": [],
   "source": [
    "# as this data frame only includes journeys that included the page_of_interest\n",
    "# we can calculate the proportion of the occurrences\n",
    "df.page_of_interest_exit_occurrences.sum() / df.Occurrences.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T22:26:08.054005Z",
     "start_time": "2019-03-02T22:26:07.762203Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.loc[df.page_of_interest_exit == True, 'page_of_interest_exit_occurrences'].values\n",
    "# mostly unique journeys, large density about one\n",
    "sns.distplot(df.loc[df.page_of_interest_exit == True, 'page_of_interest_exit_occurrences'].values);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting the number of disruptions in a journey\n",
    "To understand how this function works you can uncomment the print statements, then try running it on some test data given below.\n",
    "\n",
    "Note, that we return a logical list as we can do arithmetic on this. \n",
    "\n",
    "Another consideration is the proportion of journeys where the page_of_interest was the last in the journey as this could give us an out of range IndexError. As we can't handle exceptions in list comprehensions this is somewhat problematic. We take the shortcut of appending a made-up page to the end of every Page_List, thus dodging the error. The logic to justify this is that we assume a journey is also disrupted if it finsishes on the page_of_interest. \n",
    "\n",
    "This is a stronger assumption that we would like to make, as a journey might end on the page_of_interest as the user found what they were looking for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T23:27:35.721838Z",
     "start_time": "2019-03-02T23:27:35.703228Z"
    }
   },
   "outputs": [],
   "source": [
    "# append an arbritary placeholder to the end of the page list to dodge this problem\n",
    "# check this page does not exist on your site\n",
    "#df.loc[df.page_of_interest_exit == True, 'Page_List'] = df['Page_List'].append([\"/exit\"])\n",
    "# [[\"/a\", \"/page_of_interest\", \"/b\", \"/page_of_interest\", \"/b\", \"/page_of_interest\", \"/c\"][(i+1)] for i in [1, 3, 5]]\n",
    "# print(list(df['Page_List'])[0:][].append(\"/exit\"))\n",
    "n = df.shape[0]\n",
    "\n",
    "df['Page_List'] = [x + [y] for x, y in zip(list(df['Page_List']), list([\"/exit\"]*n))]\n",
    "df['Page_List'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T23:34:16.857747Z",
     "start_time": "2019-03-02T23:34:16.852446Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_disrupted(page_list, where_page_of_interest):\n",
    "    \"\"\"Determines if a page_list contains any disruption and counts them.\n",
    "    \n",
    "    Where disruption is interuption by a page_of_interest, so that\n",
    "     the user does not return to the earlier page. Returns an integer\n",
    "     count of the number of disruption about a page_of_interest.\n",
    "     \n",
    "     \"\"\"\n",
    "    previous_page = [page_list[(i-1)] for i in where_page_of_interest]\n",
    "    next_page = [page_list[(i+1)] for i in where_page_of_interest]\n",
    "    \n",
    "    adjacent_pages_list = [previous_page, next_page]\n",
    "    #print(adjacent_pages_list)\n",
    "    \n",
    "    disruption = list(np.array(adjacent_pages_list[0]) !=  np.array(adjacent_pages_list[1]))\n",
    "    #print(f\"Comparing the previous page with the adjacent page reveals disruption about \\\n",
    "   #each occurrence of the the page_of_interest {disruption}.\")\n",
    "    \n",
    "    disrupted = sum(map(bool, disruption))\n",
    "    #print(f\"Which gives a total of {disrupted} disruptive occurrences for this journey.\")\n",
    "    \n",
    "    return disruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T23:34:19.207323Z",
     "start_time": "2019-03-02T23:34:19.201611Z"
    }
   },
   "outputs": [],
   "source": [
    "# to understand the list comprehension used, run this example\n",
    "# note the i -1, it's getting the pages prior to the page of interest\n",
    "[[\"/a\", \"/page_of_interest\", \"/b\", \"/page_of_interest\", \"/b\", \"/page_of_interest\", \"/c\"][(i+1)] for i in [1, 3, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T23:34:19.455644Z",
     "start_time": "2019-03-02T23:34:19.450024Z"
    }
   },
   "outputs": [],
   "source": [
    "is_disrupted([\"/a\", \"/page_of_interest\", \"/b\", \"/page_of_interest\", \"/b\", \"/page_of_interest\", \"/c\"], [1, 3, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T23:28:11.822773Z",
     "start_time": "2019-03-02T23:28:11.794559Z"
    }
   },
   "outputs": [],
   "source": [
    "# df['Value'] = df.apply(lambda row: my_test(row['a'], row['c']), axis=1)\n",
    "df['disrupted'] = df.apply(lambda row: is_disrupted(row['Page_List'], row['where_page_of_interest']) , axis = 1)\n",
    "df.disrupted.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proportion of journeys that are disupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T23:37:56.383303Z",
     "start_time": "2019-03-02T23:37:56.375925Z"
    }
   },
   "outputs": [],
   "source": [
    "df.disrupted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T23:39:38.804659Z",
     "start_time": "2019-03-02T23:39:38.799033Z"
    }
   },
   "outputs": [],
   "source": [
    "# count the disruptions\n",
    "sum(x.count(True) for x in df.disrupted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T23:39:46.734275Z",
     "start_time": "2019-03-02T23:39:46.728637Z"
    }
   },
   "outputs": [],
   "source": [
    "# count the non-disruptions\n",
    "sum(x.count(False) for x in df.disrupted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T23:40:10.775648Z",
     "start_time": "2019-03-02T23:40:10.771592Z"
    }
   },
   "outputs": [],
   "source": [
    "# the number of types of joruneys\n",
    "len(df.disrupted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T23:51:28.619110Z",
     "start_time": "2019-03-02T23:51:28.597437Z"
    }
   },
   "outputs": [],
   "source": [
    "# consider journeys / occurrences affected by at least one disruption\n",
    "df['disrupted_at_least_once'] = df.apply(lambda row: any(row['disrupted']) , axis = 1)\n",
    "df['disrupted_at_least_once_occurrences'] = 0\n",
    "df.loc[df.disrupted_at_least_once == True, 'disrupted_at_least_once_occurrences'] = df['Occurrences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T23:52:39.639163Z",
     "start_time": "2019-03-02T23:52:39.414784Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(df.loc[df.disrupted_at_least_once == True, 'disrupted_at_least_once_occurrences'].values);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-02T23:53:14.317985Z",
     "start_time": "2019-03-02T23:53:14.311636Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[df.disrupted_at_least_once == True, 'disrupted_at_least_once_occurrences'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "* Was the page of interest disruptive?  \n",
    "* Was it often associated with users exiting?  \n",
    "* Did it cause much disruption to users journeys?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
