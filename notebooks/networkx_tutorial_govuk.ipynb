{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOV.UK processed network data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We work through a tutorial to learn about key network metrics and statistics. Our data is similar but different; a quirk of our data is the inclusion of non-ascii characters. We need to control for this when reading the data in.\n",
    "\n",
    "The data is from making a network out of `doo_prelim_meta_standard_with_pageseq_from_29-10_to_04-11-2018.csv.gz` which is availiable on the team drive, in the processed journey folder (the name provides info regarding the options used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use an undirected graph of friends\n",
    "import csv\n",
    "import networkx as nx\n",
    "from operator import itemgetter\n",
    "import community #This is the python-louvain package we installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple Pythonic techniques the following code makes use of. The first is list comprehensions, which embed loops (for n in nodes) to create new lists (in brackets), like so: new_list = [item for item in old_list]. The second is list slicing, which allows you to subdivide or “slice” a list. The list slicing notation [1:] takes everything except for the first item in the list. The 1 tells Python to begin with the second item in the list (in Python, you start counting at 0), and the colon tells Python to take everything up to the end of the list. Since the first line in both of these lists is the header row of each CSV, we don’t want those headers to be included in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6be82d20940c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Retrieve the data (using Python list comprhension and list slicing to remove the header row, see footnote 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# row 0 is the header, we don't want this, so we go 1: (the second row to the end)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodereader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnode_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Get a list of only the node names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-6be82d20940c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Retrieve the data (using Python list comprhension and list slicing to remove the header row, see footnote 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# row 0 is the header, we don't want this, so we go 1: (the second row to the end)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodereader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnode_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Get a list of only the node names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte"
     ]
    }
   ],
   "source": [
    "with open('../data/processed_network/for_networkx_tutorial_nodes.csv.gz', 'r', encoding='utf-8') as nodecsv: # Open the file                       \n",
    "    nodereader = csv.reader(nodecsv) # Read the csv  \n",
    "    # Retrieve the data (using Python list comprhension and list slicing to remove the header row, see footnote 3)\n",
    "    # row 0 is the header, we don't want this, so we go 1: (the second row to the end)\n",
    "    nodes = [n for n in nodereader][1:]                     \n",
    "\n",
    "node_names = [n[0] for n in nodes] # Get a list of only the node names                                       \n",
    "\n",
    "with open('../data/processed_network/for_networkx_tutorial_edges.csv.gz', 'r', encoding='utf-8') as edgecsv: # Open the file\n",
    "    edgereader = csv.reader(edgecsv) # Read the csv     \n",
    "    edges = [tuple(e) for e in edgereader][1:] # Retrieve the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n",
      "174\n"
     ]
    }
   ],
   "source": [
    "print(len(node_names))\n",
    "print(len(edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have your data as two Python lists: a list of nodes (node_names) and a list of edges (edges). In NetworkX, you can put these two lists together into a single network object that understands how nodes and edges are related. This object is called a Graph, referring to one of the common terms for data organized as a network [n.b. it does not refer to any visual representation of the data. Graph here is used purely in a mathematical, network analysis sense.] First you must initialize a Graph object with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to add our nodes and edges to the graph; let's use tab to try and workout how to do that in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_nodes_from(node_names)\n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 119\n",
      "Number of edges: 174\n",
      "Average degree:   2.9244\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a quick way of getting some general information about your graph, but as you’ll learn in subsequent sections, it is only scratching the surface of what NetworkX can tell you about your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Attributes\n",
    "For NetworkX, a Graph object is one big thing (your network) made up of two kinds of smaller things (your nodes and your edges). So far you’ve uploaded nodes and edges (as pairs of nodes), but NetworkX allows you to add attributes to both nodes and edges, providing more information about each of them. Later on in this tutorial, you’ll be running metrics and adding some of the results back to the Graph as attributes. For now, let’s make sure your Graph contains all of the attributes that are currently in our CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could do the same for our GOV.UK subgraphs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ll want to return to a list you created at the beginning of your script: nodes. This list contains all of the rows from quakers_nodelist.csv, including columns for name, historical significance, gender, birth year, death year, and SDFB ID. You’ll want to loop through this list and add this information to our graph. There are a couple ways to do this, but NetworkX provides two convenient functions for adding attributes to all of a Graph’s nodes or edges at once: `nx.set_node_attributes()` and `nx.set_edge_attributes()`. To use these functions, you’ll need your attribute data to be in the form of a Python dictionary, in which node names are the keys and the attributes you want to add are the values.5 You’ll want to create a dictionary for each one of your attributes, and then add them using the functions above. The first thing you must do is create five empty dictionaries, using curly braces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dicitonary is a key-value pair, like a word-definition pair in a traditional dictionary\n",
    "hist_sig_dict = {}\n",
    "gender_dict = {}\n",
    "birth_dict = {}\n",
    "death_dict = {}\n",
    "id_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can loop through our nodes list and add the appropriate items to each dictionary. We do this by knowing in advance the position, or index, of each attribute. Because our quaker_nodelist.csv file is well-organized, we know that the person’s name will always be the first item in the list: index 0, since you always start counting with 0 in Python. The person’s historical significance will be index 1, their gender will be index 2, and so on. Therefore we can construct our dictionaries like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that this code uses brackets in two ways. \n",
    "# It uses numbers in brackets to access specific indices within a node list (for example, the birth year at node[4]),\n",
    "# but it also uses brackets to assign a key (always node[0], the ID)\n",
    "# to any one of our empty dictionaries: dictionary[key] = value. Convenient!\n",
    "for node in nodes: # Loop through the list, one row at a time\n",
    "    hist_sig_dict[node[0]] = node[1]\n",
    "    gender_dict[node[0]] = node[2]\n",
    "    birth_dict[node[0]] = node[3]\n",
    "    death_dict[node[0]] = node[4]\n",
    "    id_dict[node[0]] = node[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have a set of dictionaries that you can use to add attributes to nodes in your Graph object. The set_node_attributes function takes three variables: the Graph to which you’re adding the attribute, the dictionary of id-attribute pairs, and the name of the new attribute. The code for adding your six attributes looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(G, hist_sig_dict, 'historical_significance')\n",
    "nx.set_node_attributes(G, gender_dict, 'gender')\n",
    "nx.set_node_attributes(G, birth_dict, 'birth_year')\n",
    "nx.set_node_attributes(G, death_dict, 'death_year')\n",
    "nx.set_node_attributes(G, id_dict, 'sdfb_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all of your nodes have these six attributes, and you can access them at any time. For example, you can print out all the birth years of your nodes by looping through them and accessing the birth_year attribute, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joseph Wyeth 1663\n",
      "Alexander Skene of Newtyle 1621\n",
      "James Logan 1674\n",
      "Dorcas Erbery 1656\n",
      "Lilias Skene 1626\n",
      "William Mucklow 1630\n",
      "Thomas Salthouse 1630\n",
      "William Dewsbury 1621\n",
      "John Audland 1630\n",
      "Richard Claridge 1649\n",
      "William Bradford 1663\n",
      "Fettiplace Bellers 1687\n",
      "John Bellers 1654\n",
      "Isabel Yeamans 1637\n",
      "George Fox the younger 1551\n",
      "George Fox 1624\n",
      "John Stubbs 1618\n",
      "Anne Camm 1627\n",
      "John Camm 1605\n",
      "Thomas Camm 1640\n",
      "Katharine Evans 1618\n",
      "Lydia Lancaster 1683\n",
      "Samuel Clarridge 1631\n",
      "Thomas Lower 1633\n",
      "Gervase Benson 1569\n",
      "Stephen Crisp 1628\n",
      "James Claypoole 1634\n",
      "Thomas Holme 1626\n",
      "John Freame 1665\n",
      "John Swinton 1620\n",
      "William Mead 1627\n",
      "Henry Pickworth 1673\n",
      "John Crook 1616\n",
      "Gilbert Latey 1626\n",
      "Ellis Hookes 1635\n",
      "Joseph Besse 1683\n",
      "James Nayler 1618\n",
      "Elizabeth Hooten 1562\n",
      "George Whitehead 1637\n",
      "John Whitehead 1630\n",
      "William Crouch 1628\n",
      "Benjamin Furly 1636\n",
      "Silvanus Bevan 1691\n",
      "Robert Rich 1607\n",
      "John Whiting 1656\n",
      "Christopher Taylor 1614\n",
      "Thomas Lawson 1630\n",
      "Richard Farnworth 1630\n",
      "William Coddington 1601\n",
      "Thomas Taylor 1617\n",
      "Richard Vickris 1590\n",
      "Robert Barclay 1648\n",
      "Jane Sowle 1631\n",
      "Tace Sowle 1666\n",
      "Leonard Fell 1624\n",
      "Margaret Fell 1614\n",
      "George Bishop 1558\n",
      "Elizabeth Leavens 1555\n",
      "Thomas Curtis 1602\n",
      "Alice Curwen 1619\n",
      "Alexander Parker 1628\n",
      "John Wilkinson 1652\n",
      "Thomas Aldam 1616\n",
      "David Barclay of Ury 1610\n",
      "David Barclay 1682\n",
      "Sir Charles Wager 1666\n",
      "George Keith 1638\n",
      "James Parnel 1636\n",
      "Peter Collinson 1694\n",
      "Franciscus Mercurius van Helmont 1614\n",
      "William Caton 1636\n",
      "Francis Howgill 1618\n",
      "Richard Hubberthorne 1628\n",
      "William Ames 1552\n",
      "William Rogers 1601\n",
      "Isaac Norris 1671\n",
      "Anthony Sharp 1643\n",
      "Mary Fisher 1623\n",
      "Anne Conway Viscountess Conway and Killultagh 1631\n",
      "Samuel Fisher 1604\n",
      "Francis Bugg 1640\n",
      "Sarah Gibbons 1634\n",
      "William Tomlinson 1650\n",
      "Humphrey Norton 1655\n",
      "William Gibson 1628\n",
      "Gideon Wanton 1693\n",
      "John Wanton 1672\n",
      "Grace Chamber 1676\n",
      "Mary Prince 1569\n",
      "John Bartram 1699\n",
      "Edward Haistwell 1658\n",
      "John ap John 1625\n",
      "John Rous 1585\n",
      "Anthony Pearson 1627\n",
      "Solomon Eccles 1617\n",
      "John Burnyeat 1631\n",
      "Edward Burrough 1633\n",
      "Rebecca Travers 1609\n",
      "William Edmundson 1627\n",
      "Sarah Cheevers 1608\n",
      "Edward Pyott 1560\n",
      "Daniel Quare 1648\n",
      "John Penington 1655\n",
      "Mary Penington 1623\n",
      "Charles Marshall 1637\n",
      "Humphrey Woolrich 1633\n",
      "William Penn 1644\n",
      "Mary Pennyman 1630\n",
      "Dorothy Waugh 1636\n",
      "David Lloyd 1656\n",
      "Lewis Morris 1671\n",
      "Martha Simmonds 1624\n",
      "John Story 1571\n",
      "Thomas Story 1670\n",
      "Thomas Ellwood 1639\n",
      "William Simpson 1627\n",
      "Samuel Bownas 1677\n",
      "John Perrot 1555\n",
      "Hannah Stranger 1656\n"
     ]
    }
   ],
   "source": [
    "for n in G.nodes(): # Loop through every node, in our data \"n\" will be the name of the person\n",
    "    print(n, G.node[n]['birth_year']) # Access every node by its name, and then by the attribute \"birth_year\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this statement, you’ll get a line of output for each node in the network. It should look like a simple list of names and years:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you’ve learned how to create a Graph object and add attributes to it. In the next section, you’ll learn about a variety of metrics available in NetworkX and how to access them. But relax, you’ve now learned the bulk of the code you’ll need for the rest of the tutorial!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready to apply to our problem?\n",
    "Now that we've done this with this example data, let's try it with out own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
